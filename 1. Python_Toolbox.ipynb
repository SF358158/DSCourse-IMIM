{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfVjXiev6w3M"
   },
   "source": [
    "# Python for Data Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jir650cm6w3P"
   },
   "source": [
    "In this notebook we introduce some of the tools that data scientists use.The  toolbox  of  any  data  scientist,  as  for  any  kind  of  programmer,  is  anessential ingredient for success and enhanced performance. Choosing the right tools can save a lot of time and thereby allow us to focus on data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2UaNT6036w3P"
   },
   "source": [
    "The  Python  community  is  one  of  the  most  active  programming  communities in the field of data science, with a huge number of developed toolboxes. The most popular python toolboxes for any data scientist are NumPy, SciPy, Pandas and Scikit-Learn.\n",
    "\n",
    "**NumPy** is  the  cornerstone  toolbox  for  scientific  computing  with  Python. NumPy provides, among other things, support for multi-dimensional arrayswith  basic  operations  on  them  and  useful  linear  algebra  functions.  Manytooboxes  use  the  NumPy  array  representations  as  an  efficient  basic  datastructure. \n",
    "\n",
    "Meanwhile, **SciPy** provides a collection of numerical algorithms and domain-specific toolboxes, including signal processing, optimization, statistics  and much  more. \n",
    "\n",
    "Another  core  toolbox is the  plotting  library **Matplotlib**. This toolbox has many tools for data visualization.\n",
    "\n",
    "**Scikit-learn** is  a  machine  learning  library  built  from  NumPy,  SciPy  and Matplotlib.  Scikit-learn  offers  simple  and  efficient  tools  for  common  tasksin data analysis such as classification, regression, clustering, dimensionalityreduction, model selection, and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJQP-Qza6w3R"
   },
   "source": [
    "**Pandas** provides high-performance data structures and data analysis tools.The key feature of Pandas is a fast and efficient DataFrame object for datamanipulation with integrated indexing. The *DataFrame* structure can be seen as a spreadsheet which offers very flexible ways of working with it. \n",
    "+ You can easily transform any dataset in the way you want, by reshaping it and addingor  removing  columns  or  rows.  \n",
    "+ It  also  provides  high-performance  functionsfor aggregating, merging and joining datasets.\n",
    "+ Pandas also has tools for importing and exporting data from different formats: comma-separated value (CSV), text files, Microsoft Excel, SQL databases, and the fast HDF5 format. \n",
    "+ In many situations, the data you have in such formats will not be complete or totally structured. For such cases, Pandas offers handling of missing data and intelligent data alignment. \n",
    "+ Furthermore, Pandas provides a convenient Matplotlib interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSf1t-ht_Aa-"
   },
   "source": [
    "## Numpy\n",
    "\n",
    "NumPy is an open-source add-on module to Python that provide common mathematical and numerical routines in pre-compiled, fast functions.\n",
    "\n",
    "There are several ways to import NumPy. The standard approach is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:11:41.735937Z",
     "start_time": "2020-02-24T16:11:41.227782Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2O_woJBk_GY5"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7Wj62cl_IhY"
   },
   "source": [
    "The central feature of NumPy is the array object class. Arrays are similar to lists in Python, except that every element of an array must be of the same type, typically a numeric type like float or int.\n",
    "\n",
    "Arrays make operations with large amounts of numeric data very fast and are generally much more efficient than lists.\n",
    "\n",
    "### Array creation\n",
    "\n",
    "There are several ways for creating an array:\n",
    "    \n",
    "+ Explicitly from a list of values.\n",
    "+ As a range of values.\n",
    "+ As a random array.\n",
    "+ By specifying the number of elements.\n",
    "+ By creating an unitializated, a zero-initializated or one-initializated array.\n",
    "+ By creating a constant diagonal value array.\n",
    "+ Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:11:44.094383Z",
     "start_time": "2020-02-24T16:11:44.090475Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aU_9zOAe_S_G",
    "outputId": "fea9e92c-55bb-4b57-f7be-8022b098b2a4"
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 4, 8, 16], float) \n",
    "print(a[:2], len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:11:47.370765Z",
     "start_time": "2020-02-24T16:11:47.363534Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "colab_type": "code",
    "id": "2rMb6HnQ_ZBb",
    "outputId": "05b2fd83-6eba-44d3-d806-d2fd9cc1e124"
   },
   "outputs": [],
   "source": [
    "print(np.arange(5, dtype=float))\n",
    "print(np.ones((2,3), dtype=float))\n",
    "print(np.zeros(7, dtype=int))\n",
    "a= np.array([[1, 2, 3], [4, 5, 6]], float) \n",
    "print(np.zeros_like(a))\n",
    "print(np.identity(4, dtype=str)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:18.496106Z",
     "start_time": "2020-02-24T16:12:18.492650Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PmxbIied_kxE",
    "outputId": "0a26153f-0392-40f8-e7f8-1f8d7038bb18"
   },
   "outputs": [],
   "source": [
    "a = np.linspace(0,100,10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:21.780838Z",
     "start_time": "2020-02-24T16:12:21.777413Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lWyG-CFZ_oVx",
    "outputId": "f5277b85-b643-45c3-e872-b600d4d1491c"
   },
   "outputs": [],
   "source": [
    "a = np.linspace(10,100,10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:23.124710Z",
     "start_time": "2020-02-24T16:12:23.116398Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "c64rtNmS_qnV",
    "outputId": "d6f3fac8-89ec-4944-dcce-0e3bec989b57"
   },
   "outputs": [],
   "source": [
    "np.random.rand(2,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:24.796912Z",
     "start_time": "2020-02-24T16:12:24.792572Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "7FDU0RVA_s5k",
    "outputId": "f8c4e274-9245-4e07-f4cc-38c786cfe0a5"
   },
   "outputs": [],
   "source": [
    "a = np.random.normal(size=5) \n",
    "b = np.random.normal(5, size=5)         # mean = 5\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:28.692894Z",
     "start_time": "2020-02-24T16:12:28.687470Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "b145Gbh0_yl5"
   },
   "outputs": [],
   "source": [
    "np.random.normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5AP840T_3vf"
   },
   "source": [
    "Arrays can be multidimensional. **Unlike lists**, different axes are accessed using commas inside \n",
    "bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:37.386107Z",
     "start_time": "2020-02-24T16:12:37.382068Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "c0RYUl50_40t",
    "outputId": "c87a3c31-1b32-44be-bf56-320c406f8e69"
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]], int)\n",
    "print(a[0,0])                # different axes are accessed using commas inside bracket notation\n",
    "print(a[-1:,-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9Dqugdr__pT"
   },
   "source": [
    "Object arrays have several properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:38.599102Z",
     "start_time": "2020-02-24T16:12:38.595900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rC75F792AASJ",
    "outputId": "3546d723-917b-4a9f-c82d-d943cbdbaf62"
   },
   "outputs": [],
   "source": [
    "print(a.shape, a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXM5HzYiAJFJ"
   },
   "source": [
    "The ``in`` statement can be used to test if values are present in an array: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:40.883331Z",
     "start_time": "2020-02-24T16:12:40.879760Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Byut5QaNAJqY"
   },
   "outputs": [],
   "source": [
    "2 in a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tr5UQGMAOHZ"
   },
   "source": [
    "Arrays can be reshaped using tuples that specify new dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:48.691499Z",
     "start_time": "2020-02-24T16:12:48.688388Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "xWBs_OBxAPJD",
    "outputId": "aad94419-6d8c-403f-8574-22d2fb78ef56"
   },
   "outputs": [],
   "source": [
    "a = a.reshape((3, 2))    # this function creates a new array!\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqCWwf8CAU3k"
   },
   "source": [
    "Lists can also be created from arrays: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:51.154804Z",
     "start_time": "2020-02-24T16:12:51.150824Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4N6rOtBDAUIY",
    "outputId": "716c7688-130d-423e-a646-8c9977edac7d"
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3], float) \n",
    "type(a.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cNAqwvoAZ7m"
   },
   "source": [
    "Other functions and properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:53.534668Z",
     "start_time": "2020-02-24T16:12:53.524755Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "TybKF8FAAaXR",
    "outputId": "b853f984-2bea-4c7c-86bf-9200341302c7"
   },
   "outputs": [],
   "source": [
    "a = np.array(range(6), float).reshape((2, 3)) \n",
    "a.transpose()   # Transposed versions of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:56.475911Z",
     "start_time": "2020-02-24T16:12:56.472408Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Qat0PUxyAdDP"
   },
   "outputs": [],
   "source": [
    "a.flatten()    # One-dimensional versions of multi-dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:12:57.536329Z",
     "start_time": "2020-02-24T16:12:57.530253Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OZfmVROoAe31"
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2], float) \n",
    "b = np.array([3,4,5,6], float) \n",
    "c = np.array([7,8,9], float) \n",
    "np.concatenate((a, b, c)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:05.073502Z",
     "start_time": "2020-02-24T16:13:05.068272Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DahPWp-GAhG4"
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]], float) \n",
    "b = np.array([[5, 6], [7,8]], float) \n",
    "np.concatenate((a,b), axis=0)      # it is possible to specify the axis for concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:15.434724Z",
     "start_time": "2020-02-24T16:13:15.430156Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2jnFzcFHAkzZ"
   },
   "outputs": [],
   "source": [
    "np.concatenate((a,b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:26.083068Z",
     "start_time": "2020-02-24T16:13:26.071507Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JB-mDAlnAmzj",
    "outputId": "0ccb5e6f-2ed4-4f2a-b1f8-bafc80ad8669"
   },
   "outputs": [],
   "source": [
    "a = np.array([2, 4, 3], float) \n",
    "print(a.sum(), a.prod(), a.mean(), a.var(), a.std(), a.min(), a.max())\n",
    "print(a.argmin(), a.argmax())     # these functions return the array indices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoB0mfjlAsIo"
   },
   "source": [
    "One dimensional arrays have a 1-tuple for their shape: <code> (size,)</code>.\n",
    "\n",
    "N-dimensional arrays have a N-tuple for their shape: <code> (size1, ..., sizeN)</code>.\n",
    "\n",
    "For multidimensional arrays, each of the functions thus far described can take an optional \n",
    "argument ``axis`` that will perform an operation along only the specified axis, placing the results in a return array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:37.158307Z",
     "start_time": "2020-02-24T16:13:37.153450Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "as3mudE-Aswt"
   },
   "outputs": [],
   "source": [
    "a = np.array([[0, 2], [3, -1], [3, 5]], float) \n",
    "print(a)\n",
    "print(a.mean(axis=0), a.mean(axis=1), a.min(axis=1), a.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Pf2_GW4A2uD"
   },
   "source": [
    "### Indexing and Slicing\n",
    "\n",
    "**Simple assigments do not make copies of arrays. Slicing operations do not make copies either; they return views on the original array**.\n",
    "\n",
    "Array views contain a pointer to the original data, but may have different\n",
    "shape or stride values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:52.422923Z",
     "start_time": "2020-02-24T16:13:52.419662Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "id": "CuOP32ZpA5Lq",
    "outputId": "40e7e6e0-c3b0-4bf9-f421-11025f86eee5"
   },
   "outputs": [],
   "source": [
    "a = np.array(range(64)).reshape((8,8))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:55.529419Z",
     "start_time": "2020-02-24T16:13:55.526079Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6-NPa2fAA-Ri",
    "outputId": "06f51912-b0a8-4717-bfdb-a1b40e4022d5"
   },
   "outputs": [],
   "source": [
    "print(a[0:2,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:56.496171Z",
     "start_time": "2020-02-24T16:13:56.493186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M9uCVcfZBCE9",
    "outputId": "1ebd6d48-a773-4f90-acea-13e82e4e0e65"
   },
   "outputs": [],
   "source": [
    "print(a[2,1:])  # This is an element!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:57.350868Z",
     "start_time": "2020-02-24T16:13:57.347824Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cNEmpXlvBENF",
    "outputId": "5799a805-45b4-4aff-d57e-3f0c9dd5a140"
   },
   "outputs": [],
   "source": [
    "print(a[0,1:]) # This is an element!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:13:58.094623Z",
     "start_time": "2020-02-24T16:13:58.091556Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "v_F1clbqBKg7",
    "outputId": "adc94aa8-4286-47dd-ab32-d054d43a10f3"
   },
   "outputs": [],
   "source": [
    "print(a[:2,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:14:00.546668Z",
     "start_time": "2020-02-24T16:14:00.543459Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "id": "UOd7LLVyBPbD",
    "outputId": "3152299d-23d7-42ff-bdb7-9a6de16afcb1"
   },
   "outputs": [],
   "source": [
    "print(a[:,::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:14:01.361892Z",
     "start_time": "2020-02-24T16:14:01.352941Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "wPjLYAapBTH1",
    "outputId": "383c4fe3-c9f3-4970-c06f-46ad6038c93f"
   },
   "outputs": [],
   "source": [
    "print(a[::2,::3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MAlHiMNBY8J"
   },
   "source": [
    "### Array operations\n",
    "\n",
    "Standard mathematical operations are applied on an **element-by-element basis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:14:05.508156Z",
     "start_time": "2020-02-24T16:14:05.503712Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dg1zFgnGBZvY",
    "outputId": "dff013f2-7142-4bfa-98a4-bf43b3ffb066"
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3], float) \n",
    "b = np.array([5,2,6], float) \n",
    "print(a + b, a % b, a ** b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJATE8WkBfpo"
   },
   "source": [
    "For two-dimensional arrays, multiplication remains elementwise and does not correspond to matrix multiplication. There are special functions for matrix math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:14:10.539800Z",
     "start_time": "2020-02-24T16:14:10.534639Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "t9o5D0LIBgQ9",
    "outputId": "16292199-d2b4-40be-9de6-f8144bd244a0"
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4]], float) \n",
    "b = np.array([[2,0], [1,3]], float) \n",
    "a * b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPxelfQFBlz_"
   },
   "source": [
    "Arrays that do not match in the number of dimensions will be **broadcasted** by Python \n",
    "to perform mathematical operations. This often means that the smaller array will be repeated \n",
    "as necessary to perform the operation indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:14:31.237833Z",
     "start_time": "2020-02-24T16:14:31.232749Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "4CAe8b6zBmlz",
    "outputId": "19f323b3-2d82-4aa6-f84f-95180258c51d"
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4], [5, 6]], float) \n",
    "b = np.array([-1, 3], float) \n",
    "print(a , b)\n",
    "print() \n",
    "print(a + b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhQ8BbfPBuV2"
   },
   "source": [
    "Sometimes, however, we can use the ``newaxis`` constant to specify how we \n",
    "want to broadcast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T10:53:05.483237Z",
     "start_time": "2019-11-12T10:53:05.474781Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "cCa7n4vrBu4f",
    "outputId": "617be9dc-57d6-4404-f486-6daada0df9dc"
   },
   "outputs": [],
   "source": [
    "a = np.zeros((2,2), float) \n",
    "b = np.array([-1., 3.], float) \n",
    "print(a, b)\n",
    "print()\n",
    "print(a + b) \n",
    "print()\n",
    "print(a + b[np.newaxis,:])\n",
    "print()\n",
    "print(a + b[:,np.newaxis]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faeY7UUUB6JB"
   },
   "source": [
    "NumPy offers a large library of common mathematical functions that can be applied elementwise to arrays. Among these are the functions: <code> abs,sign, sqrt, log, log10, exp, sin, cos, tan, arcsin, arccos, arctan, sinh, cosh, tanh, arcsinh, arccosh, </code> and <code>arctanh </code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:15:34.587022Z",
     "start_time": "2020-02-24T16:15:34.582874Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "shicMJjmB8pK",
    "outputId": "a57802b7-90d1-42fa-ed05-daedaad74f95"
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 4, 9], float) \n",
    "np.sin(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SiG3-haGCASF"
   },
   "source": [
    "It is possible to iterate over arrays in a manner similar to that of lists: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:15:35.778880Z",
     "start_time": "2020-02-24T16:15:35.774790Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "k4tQ0GWYCA4U",
    "outputId": "ebc70b70-65e6-4439-e1c7-76c9fd3e6ed0"
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4], [5, 6]], float) \n",
    "for x in a: \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:15:47.198881Z",
     "start_time": "2020-02-24T16:15:47.195458Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "OW4nSQ6ECGPt",
    "outputId": "60eabf8c-a8c0-4336-8b1a-7e6427738041"
   },
   "outputs": [],
   "source": [
    "for [x, y] in a:             # Multiple assignment can also be used with array iteration\n",
    "    print(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18Ry3C7vCNz8"
   },
   "source": [
    "### Comparison operators and value testing \n",
    "Boolean comparisons can be used to compare members elementwise on arrays of equal size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:15:51.478802Z",
     "start_time": "2020-02-24T16:15:51.468849Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "s2fY5xriCOah",
    "outputId": "ad158ad9-d110-44f5-92aa-3727c7352eb9"
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 3, 0], float) \n",
    "b = np.array([0, 3, 2], float) \n",
    "print(a > b)\n",
    "print(a == b) \n",
    "print(a <= b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvqVClRuCcd_"
   },
   "source": [
    "### Array item selection and manipulation \n",
    "We can use array selectors to **filter** for specific subsets of elements of other arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:15:54.431424Z",
     "start_time": "2020-02-24T16:15:54.427195Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "wTLvzIcaCeEH",
    "outputId": "3f6bb7dc-c304-4e69-d8c2-00855ed0fec9"
   },
   "outputs": [],
   "source": [
    "a = np.array([[6, 4], [5, 9]], float) \n",
    "a >= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:15:57.818357Z",
     "start_time": "2020-02-24T16:15:57.814392Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VkmRWFg9Cifp",
    "outputId": "b1ef098e-a705-42b8-975c-0b0c9b17b9ad"
   },
   "outputs": [],
   "source": [
    "a[a >= 6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:15:59.416450Z",
     "start_time": "2020-02-24T16:15:59.411943Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TNh3MPenCmNZ",
    "outputId": "c73f886f-8c50-4ec3-d4e9-b5e49ff5561d"
   },
   "outputs": [],
   "source": [
    "a = np.array([[6, 4], [5, 9]], float) \n",
    "sel = (a >= 6) \n",
    "a[sel] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qg-LECKRCsWn"
   },
   "source": [
    "### Vector and matrix mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:16:31.237912Z",
     "start_time": "2020-02-24T16:16:31.227140Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h9Di1dlvCtBc",
    "outputId": "c6440f83-71d3-402e-b2be-ba37114a34b5"
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3], float) \n",
    "b = np.array([0, 1, 1], float) \n",
    "np.dot(a, b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:16:31.936264Z",
     "start_time": "2020-02-24T16:16:31.925456Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "kYU0e3L6CvS3",
    "outputId": "0c89ec29-2c95-4002-ef31-4b20957806db"
   },
   "outputs": [],
   "source": [
    "a = np.array([[0, 1], [2, 3]], float) \n",
    "b = np.array([2, 3], float) \n",
    "c = np.array([[1, 1], [4, 0]], float) \n",
    "print(np.dot(b, a))\n",
    "print(np.dot(a, c)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKskXI3EC8Sk"
   },
   "source": [
    "NumPy also comes with a number of built-in routines for linear algebra calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:16:33.913747Z",
     "start_time": "2020-02-24T16:16:33.769371Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8Ryp9fTSC-zT",
    "outputId": "f957d515-caa1-4b3d-e6f5-dc55591bc86c"
   },
   "outputs": [],
   "source": [
    "a = np.array([[4, 2, 0], [9, 3, 7], [1, 2, 1]], float)\n",
    "np.linalg.det(a)                 # These can be found in the sub-module linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:16:35.617485Z",
     "start_time": "2020-02-24T16:16:35.603873Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "SrvmtvyvDCa3",
    "outputId": "e31c626d-e032-45a0-a812-a45aeb50ba62"
   },
   "outputs": [],
   "source": [
    "vals, vecs = np.linalg.eig(a)\n",
    "print(vals)\n",
    "print()\n",
    "print(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:16:36.220869Z",
     "start_time": "2020-02-24T16:16:36.211747Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "xmnES8_bDI0s",
    "outputId": "28591e5c-2333-467b-8472-a191ff0c685f"
   },
   "outputs": [],
   "source": [
    "b = np.linalg.inv(a) \n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjXeXdAd-tIa"
   },
   "source": [
    "## Pandas\n",
    "\n",
    "Let us begin by importing those packages that we will need for our program. In the first cell we put the code to import the `pandas` library as `pd`. This is for convenience; every time we need to use some functionality from the pandas library, we will write `pd` instead of `pandas`. We will also import the two core libraries mentioned also in the book chapter `numpy` library as `np` and `matplotlib.pyplot` library as `plt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:16:54.350483Z",
     "start_time": "2020-02-24T16:16:54.347119Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NsTROnyq6w3R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='times')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10) \n",
    "plt.rc('font', size=12) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rychNj7l6w3U"
   },
   "source": [
    "### DataFrames \n",
    "\n",
    "The key data structure in Pandas is the **DataFrame** object. A DataFrame is basically a tabular data structure, with rows and columns. Rows have a specific index to access them, which can be any name or value. \n",
    "\n",
    "In Pandas, the columns are called **Series**, a special type of data, which in essence consists of a list of several values, where each value has an index. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWZObSpH6w3U"
   },
   "source": [
    "### Creating a new DataFrame from the scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_kiSLR_6w3V"
   },
   "source": [
    "To understand how it works, let us see how to create a `DataFrame` from a common Python dictionary of lists.\n",
    "\n",
    "\n",
    "In this example, we use the pandas `DataFrame` object constructor with a dictionary of lists as argument.\n",
    "\n",
    "The value of each entry in the dictionary is the name of the column, and the lists are their values. \n",
    "The DataFrame columns can be arranged at construction time by entering a keyword *columns* with a list of the names of the columns ordered as we want. If the column keyword is not present in the constructor, the columns will be arranged in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:00.704268Z",
     "start_time": "2020-02-24T16:17:00.641902Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "urqvV9Px6w3V",
    "outputId": "64451618-ea23-4f65-d55d-feedf67b6910"
   },
   "outputs": [],
   "source": [
    "data = {'year': [2010,2011,2012,2010,2011,2012,2010,2011,2012],\n",
    "        'team': ['FCBarcelona','FCBarcelona','FCBarcelona', 'RMadrid','RMadrid','RMadrid', 'ValenciaCF',\n",
    "                 'ValenciaCF','ValenciaCF'],\n",
    "        'wins':   [30,28,32,29,32,26,21,17,19],\n",
    "        'draws':  [6,7,4,5,4,7,8,10,8],\n",
    "        'losses': [2,3,2,4,2,5,9,11,11]\n",
    "        }\n",
    "football = pd.DataFrame(data, columns=['year','team','wins','draws','losses'])\n",
    "football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SX_l5gY56w3Y"
   },
   "source": [
    "The result is a table where each entry in the dictionary is a column. \n",
    "\n",
    "The index of each row is created automatically taking the position of its elements inside the entry lists, starting from 0.\n",
    "\n",
    "Although it is very easy to create DataFrames from scratch, most of the time what we will need to do is import chunks of data into a `DataFrame` structure, we will see how to do this in later examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGZ0QRYT6w3Z"
   },
   "source": [
    "### Open government data analysis example using Pandas\n",
    "\n",
    "To illustrate how we can use Pandas in a simple real problem, we will start doing some basic analysis of government data. For the sake of transparency, data produced by government entities must be open, meaning that they can be freely used, reused and distributed by anyone. An example of this is the Eurostat, which is the home of European Commission data. \n",
    "\n",
    "Eurostat’s main role is to process and publish comparable statistical information at the European level. The data in Eurostat are provided by each member state and it is free to reuse them, both for noncommercial and commercial purposes (with some minor exceptions).  \n",
    "\n",
    "\n",
    "Since the amount of data in the Eurostat database is huge, in our first study we are only going to focus on data relative to indicators of educational funding by the member states. Thus, the first thing to do is to retrieve such data from Eurostat. \n",
    "\n",
    "Since open data have to be delivered in a plain text format, CSV (or any other delimiter-separated value) formats are commonly used to store tabular data. In a delimiter-separated value file, each line is a data record and each record consists of one or more fields, separated by the delimiter character (usually a comma). Therefore, the data we will use can be found already downloaded and preprocessed as a CSV file *educ_figdp_1_Data.csv* which can be download from Github. \n",
    "\n",
    "It can also be downloaded as unprocessed tabular data from the Eurostat database site [Eurostat database site]( http://ec.europa.eu/eurostat/data/database) \n",
    "following the path:  `Tables by themes > Population and social conditions > \n",
    "Education and training > Education > Indicators on education finance > Public expenditure on education` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZHUlFML6w3Z"
   },
   "source": [
    "## Reading tabular data\n",
    "\n",
    "Let us start reading the data we downloaded.\n",
    "The way to read CSV (or any other separated value, providing the separator character) files in Pandas is by calling the `read_csv` method. Besides the name of the file, we add the *na_values* key argument to this method along with the character that represents \"non available data\" in the file. Normally, CSV files have a header with the names of the columns. If this is the case,  we can use the *usecols* parameter to select which columns in the file will be used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:19.124435Z",
     "start_time": "2020-02-24T16:17:19.097677Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "M6ORqQWy6w3a",
    "outputId": "987869a7-29a5-4e47-c0e2-8886eb13a6dd"
   },
   "outputs": [],
   "source": [
    "edu=pd.read_csv('educ_figdp_1_Data.csv',na_values=':',usecols=[\"TIME\",\"GEO\",\"Value\"])\n",
    "edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnwKfCjV6w3c"
   },
   "source": [
    "In this case, the DataFrame resulting from reading our data is stored in **edu**. The output of the execution shows that the `edu` DataFrame size is 384 rows $\\times$ 3 columns. Since the DataFrame is too large to be fully displayed, three dots appear in the middle of each row.\n",
    "\n",
    "\n",
    "Beside this, Pandas also has functions for reading files with formats such as Excel, HDF5, tabulated files or even the content from the clipboard (`read_excel(), read\\_hdf(), read\\_table(), read\\_clipboard()`). Whichever function we use, the result of reading a file is stored as a DataFrame structure. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xE-4dmkT6w3c"
   },
   "source": [
    "## Viewing Data\n",
    "\n",
    "To see how the data looks, we can use the `head()` method, which shows just the first five rows. if we put a number as an argument to this method, this will be the number of the first rows that are listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:29.869472Z",
     "start_time": "2020-02-24T16:17:29.862665Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "q8N8kaJc6w3d",
    "outputId": "c5dc80e7-ecaa-4321-bbfa-4329b74da886"
   },
   "outputs": [],
   "source": [
    "edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yd5h3HrF6w3e"
   },
   "source": [
    "Similarly, it exists the **tail()** method, which returns the last five rows by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:33.818482Z",
     "start_time": "2020-02-24T16:17:33.811740Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZiSxnNeH6w3f",
    "outputId": "256e6cbf-a845-4135-d515-981e6deca89f"
   },
   "outputs": [],
   "source": [
    "edu.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5W3cTo-N6w3h"
   },
   "source": [
    "If we want to know the names of the columns or the names of the indexes, we can use the DataFrame attributes **columns** and **index** respectively. The names of the columns or indexes can be changed by assigning a new list of the same length to these attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:35.593794Z",
     "start_time": "2020-02-24T16:17:35.589840Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NqAMs7aV6w3i",
    "outputId": "8ab11deb-6506-4b13-92b2-ea1074e91ad7"
   },
   "outputs": [],
   "source": [
    "edu.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:37.855195Z",
     "start_time": "2020-02-24T16:17:37.851496Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1oIpgODZ6w3l",
    "outputId": "c23cf897-1796-4b34-8022-3c1b96a3c438"
   },
   "outputs": [],
   "source": [
    "edu.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqsrLTps6w3n"
   },
   "source": [
    "The values of any DataFrame can be retrieved as a Python array by calling its **values ** attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:39.474275Z",
     "start_time": "2020-02-24T16:17:39.470191Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BgSJu9_L6w3o",
    "outputId": "e026705f-f7f3-4e9d-cadb-178fbdaed381"
   },
   "outputs": [],
   "source": [
    "edu.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59-se87A6w3p"
   },
   "source": [
    "If we just want quick statistical information on all the numeric columns in a data frame, we can use the function **describe()**. The result shows the count, the mean, the standard deviation, the minimum and maximum, and the percentiles, by default, the 25th, 50th, and 75th, for all the values in each column or series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:47.717113Z",
     "start_time": "2020-02-24T16:17:47.695431Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "N_g8Ym0o6w3q",
    "outputId": "21461098-1af8-4ac6-bbb0-05c564d4a07f"
   },
   "outputs": [],
   "source": [
    "edu.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEBKHmqd6w3s"
   },
   "source": [
    "## Selection\n",
    "\n",
    "If we want to select a subset of data from a DataFrame, it is necessary to indicate this subset using square brackets `[]` after the DataFrame. The subset can be specified in several ways. If we want to select only one column from a DataFrame, we only need to put its name between the square brackets. The result will be a Series data structure, not a DataFrame, because only one column is retrieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:54.596157Z",
     "start_time": "2020-02-24T16:17:54.590751Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QggpIgEg6w3s",
    "outputId": "ba7472e3-5ee3-4815-cd06-078f807d530c"
   },
   "outputs": [],
   "source": [
    "edu['Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIBjMl2R6w3u"
   },
   "source": [
    "If we want to select a subset of rows from a DataFrame, we can do so by indicating a range of rows separated by `:` inside the square brackets. This is commonly known as a *slice* of rows.\n",
    "\n",
    "Next instruction returns the slice of rows from the 10th to the 13th position. Note that the slice does not use the index labels as references, but the position. In this case, the labels of the rows simply coincide with the position of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:17:55.823411Z",
     "start_time": "2020-02-24T16:17:55.816719Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "THZiqarK6w3u",
    "outputId": "d7102f62-9440-4963-cf7f-a446ad03cc27"
   },
   "outputs": [],
   "source": [
    "edu[10:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qiHFnQho6w3x"
   },
   "source": [
    " If we want to select a subset of columns and rows using the labels as our references instead of the positions, we can use `loc` indexing:\n",
    "\n",
    "Next instruction  will return all the rows between the indexes specified in the slice before the comma, and the columns specified as a list after the comma. In this case, `loc` references the index labels, which means that  `loc` does not return the 90th to 94th rows, but it returns all the rows between the row labeled 90 and the row labeled 94; thus if the index 100 is placed between the rows labeled as 90 and 94, this row would also be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:18:14.934263Z",
     "start_time": "2020-02-24T16:18:14.920241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "G3pvdBmw6w3z",
    "outputId": "fd52e6ee-5e25-49f2-e10f-5f888452d0c8"
   },
   "outputs": [],
   "source": [
    "edu.loc[90:94,['TIME','GEO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOqIGuVq6w31"
   },
   "source": [
    "## Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utB0FYhp6w31"
   },
   "source": [
    "Another way to select a subset of data is by applying Boolean indexing. This indexing is commonly known as a *filter*. For instance, if we want to filter those values less than or equal to 6.5, we can do it like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:18:22.358516Z",
     "start_time": "2020-02-24T16:18:22.345043Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PQWv9Suv6w32",
    "outputId": "f99c9df5-e3f2-4998-f7b5-22c175064171"
   },
   "outputs": [],
   "source": [
    "edu[edu['Value'] > 6.5].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5B2n8_x76w33"
   },
   "source": [
    "Boolean indexing uses the result of a Boolean operation over the data, returning a mask with True or False for each row. The rows marked True in the mask will be selected. In the previous example, the Boolean operation `edu['Value'] > 6.5` produces a Boolean mask. When an element in the *\"Value\"* column is greater than 6.5, the corresponding value in the mask is set to True, otherwise it is set to False. Then, when this mask is applied as an index in `edu[edu['Value'] > 6.5]`, the result is a filtered DataFrame containing only rows with values higher than 6.5. Of course, any of the usual Boolean operators can be used for filtering: `<` (less than),  `<= ` (less than or equal to),  `> ` (greater than),  `>=` (greater than or equal to),  `=`  (equal to),  `!= `(not equal to)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPjdi9jh6w34"
   },
   "source": [
    "## Filtering Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRXIWJUQ6w34"
   },
   "source": [
    "Pandas uses the special value **NaN** (not a number) to represent missing values. In Python, `NaN` is a special floating-point value returned by certain operations when one of their results ends in an undefined value. A subtle feature of `NaN` values is that two `NaN` are never equal. Because of this, the only safe way to tell whether or not a value is missing in a DataFrame is by using the `isnull()` function. Indeed, this function can be used to filter rows with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:18:36.156434Z",
     "start_time": "2020-02-24T16:18:36.148878Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hW9-4noW6w35",
    "outputId": "8587c456-15b7-44f2-93c7-a7c98d619755"
   },
   "outputs": [],
   "source": [
    "edu[ edu[\"Value\"].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUD2Hvxn6w3-"
   },
   "source": [
    "## Manipulating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7kWgPX36w3_"
   },
   "source": [
    "Once we know how to select the desired data, the next thing we need to know is how to manipulate data. \n",
    "One of the most straightforward things we can do is to operate with columns or rows  using aggregation functions. The following list shows the most common aggregation functions.\n",
    "\n",
    "| Function  | Description | \n",
    "|-----------|-------------|\n",
    "| count()   |Number of non-null observations|  \n",
    "| sum()     |Sum of values|\n",
    "| mean()    |Mean of values            | \n",
    "| median()  |Arithmetic median of values             |\n",
    "| min()     |Minimum|\n",
    "| max()     |Maximum|\n",
    "| prod()    |Product of values|\n",
    "| std()     |Unbiased standard deviation|\n",
    "| var()     | Unbiased variance|\n",
    "\n",
    "The result of all these functions applied to a row or column is always a number. Meanwhile, if a function is applied to a DataFrame or a selection of rows and columns, then you can specify if the function should be applied to the rows for each column  (putting the **axis=0** keyword on the invocation of the function), or it should be applied on the columns for each row (putting the **axis=1** keyword on the invocation of the function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:19:20.007892Z",
     "start_time": "2020-02-24T16:19:20.002599Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5N0fFodq6w3_",
    "outputId": "d52ebd5d-112c-4e52-811f-f06774bfafd3"
   },
   "outputs": [],
   "source": [
    "edu.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXoE0abG6w4B"
   },
   "source": [
    "\n",
    "Note that these are functions specific to Pandas, not the generic Python functions. There are differences in their implementation. In Python ,`NaN` values propagate through all operations without raising an exception. In contrast, Pandas operations exclude `NaN` values representing missing data. For example, the pandas **max** function excludes `NaN`  values, thus they are interpreted as missing values, while the standard Python **max** function will take the mathematical interpretation of `NaN` and return it as the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:19:26.182808Z",
     "start_time": "2020-02-24T16:19:26.178535Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gVkTR_Ac6w4C",
    "outputId": "8e37679c-33f7-4404-f35d-1c38b250f82d"
   },
   "outputs": [],
   "source": [
    "print(\"Pandas max function:\", edu[\"Value\"].max())\n",
    "print(\"Python max function:\", max(edu[\"Value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7g9r51s6w4F"
   },
   "source": [
    "Beside these aggregation functions, we can apply operations over all the values in rows, columns or a selection of both. The rule of thumb is that an operation between columns means that it is applied to each row in that column and an operation between rows means that it is applied to each column in that row. For example we can apply any binary arithmetical operation (`+,-,*,/`) to an entire column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:20:27.890416Z",
     "start_time": "2020-02-24T16:20:27.885411Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BgLgIA6F6w4F",
    "outputId": "9f0fbfff-ebe0-4cd3-9a5c-941cf2f468c2"
   },
   "outputs": [],
   "source": [
    "s=edu[\"Value\"]/100\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S11mXUFo6w4H"
   },
   "source": [
    "However, we can apply any function to a DataFrame or Series just putting its name as argument  of the **apply** method. For example, in the following code, we apply the  **sqrt** function from the *numpy* library to perform the square root of each value in the *\"Value\"* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T10:55:44.971948Z",
     "start_time": "2019-11-12T10:55:44.966489Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jcJorijh6w4H",
    "outputId": "7a18c9c2-10f7-4189-cb04-6312a1bc48d8"
   },
   "outputs": [],
   "source": [
    "s = edu[\"Value\"].apply(np.sqrt)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9m7_9gn6w4K"
   },
   "source": [
    "If we need to design a specific function to apply it, we can write an in-line function, commonly known as a $\\lambda$-function. A $\\lambda$-function is a function without a name. It is only necessary to specify the parameters it receives, between the **lambda**  keyword and the **:**. In the next example, only one parameter is needed, which will be the value of each element in the *\"Value\"* column. The value the function returns will be the square of that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:20:52.743796Z",
     "start_time": "2020-02-24T16:20:52.738084Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "M5SSfBNW6w4L",
    "outputId": "dd1f0a97-81ed-4543-d92a-2ee2bdcf6434"
   },
   "outputs": [],
   "source": [
    "s = edu[\"Value\"].apply(lambda d: d**2)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEa8AL-v6w4O"
   },
   "source": [
    "Another basic manipulation operation is to set new values in our DataFrame. This can be done directly using the assign operator **=** over a DataFrame. For example, to add a new column to a DataFrame, we can assign a Series to a selection of a column that does not exist. This will produce a new column in the DataFrame after all the others. You must be aware that if a column with the same name already exists, the previous values will be overwritten. In the following example, we assign the Series that results from dividing the \"Value\" column by the maximum value in the same column to a new column named \"ValueNorm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:20:54.480699Z",
     "start_time": "2020-02-24T16:20:54.470428Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TlLNCa7e6w4P",
    "outputId": "40fc9148-d9ac-4fc0-e9fc-b9575e0978e1"
   },
   "outputs": [],
   "source": [
    "edu[\"ValueNorm\"] = edu['Value']/edu['Value'].max()\n",
    "edu.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgNa6ryK6w4S"
   },
   "source": [
    "Now, if we  want to remove this column from the DataFrame, we can use the **drop** function; this removes the indicated rows if **axis=0**,  or the indicated columns if **axis=1**. In Pandas, all the functions that change the contents of a DataFrame, such as the drop function, will normally return a copy of the modified data, instead of overwriting the DataFrame. Therefore, the original DataFrame is kept. If you do not want to keep the old values, you can set the keyword **inplace** to `True`. By default, this keyword is set to `False`, meaning that a copy of the data is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:21:21.012119Z",
     "start_time": "2020-02-24T16:21:20.997170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Cfl-Qzbd6w4T",
    "outputId": "df82e22a-7393-4402-c4b4-7e915b2f9787"
   },
   "outputs": [],
   "source": [
    "edu.drop('ValueNorm',axis=1,inplace=True)\n",
    "edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgttktGu6w4W"
   },
   "source": [
    "Instead, if what we want to do is to insert a new row at the bottom of the DataFrame, we can use the Pandas **append** function. This functions receives as argument the new row, which is represented as a dictionary where the keys are the name of the columns and the values the associated value. You must be aware to setting  the **ignore_index** flag in the **append** method  to `True`, otherwise the index 0 is given to this new row, what will produce an error if it already exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:21:44.835269Z",
     "start_time": "2020-02-24T16:21:44.825655Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "54ozmwyT6w4Y",
    "outputId": "0a8aba43-d85b-41c0-ed1d-365bdbe46dab"
   },
   "outputs": [],
   "source": [
    "edu = edu.append({\"TIME\":2000,\"Value\":5.00,\"GEO\":'a'}, ignore_index=True)\n",
    "edu.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmdGYaGk6w4a"
   },
   "source": [
    "Finally, if we want to remove this row, we need to use the **drop** function again. Now we have to set the axis to 0, and specify the index of the row we want to remove. Since we want to remove the last row, we can use the max function over the indexes to determine which row is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:21:49.700187Z",
     "start_time": "2020-02-24T16:21:49.685936Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Hqb1dEL56w4b",
    "outputId": "1d6f329b-5483-4495-8224-6ec8e5efbec3"
   },
   "outputs": [],
   "source": [
    "edu.drop(max(edu.index),axis=0,inplace=True)\n",
    "edu.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ry_1GuEI6w4h"
   },
   "source": [
    "To remove `NaN` values, instead of the generic drop function, we can use the specific `dropna()` function. If we want to erase any row that contains an `NaN` value, we have to set the `how` keyword to *any*. To restrict it to a subset of columns, we can specify it using the `subset` keyword. As we can see below, the result will we the same as using the `drop` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:22:12.633750Z",
     "start_time": "2020-02-24T16:22:12.624756Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "N6XsUzRw6w4h",
    "outputId": "a272dc24-6c38-4356-a02b-c9e77a5c3119"
   },
   "outputs": [],
   "source": [
    "eduDrop = edu.dropna(how='any',subset=[\"Value\"],axis=0)\n",
    "eduDrop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8k-Chc96w4j"
   },
   "source": [
    "If, instead of removing the rows containing `NaN`, we want to fill them with another value, then we can use the ``fillna()`` method, specifying which value has to be used. If we want to fill only some specific columns, we have to put as argument to the ``fillna()`` function a dictionary with the name of the columns as the key and which character to be used for filling as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T10:57:00.172505Z",
     "start_time": "2019-11-12T10:57:00.163392Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wbCoVzl_6w4k",
    "outputId": "6d4080dc-22ab-4798-d533-0d4247d29076"
   },
   "outputs": [],
   "source": [
    "eduFilled  = edu.fillna(value={\"Value\":0}) \n",
    "eduFilled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWwV40r46w4o"
   },
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqfqTGky6w4o"
   },
   "source": [
    "Another important functionality we will need when inspecting our data is to sort by columns. We can sort a DataFrame using any column, using the `sort` function.  If we want to see the first five rows of data sorted in descending order  (i.e., from the largest to the smallest values) and using the *\"Value\"* column, then we just need to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:22:32.051243Z",
     "start_time": "2020-02-24T16:22:32.043015Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MHhhRkpc6w4p",
    "outputId": "56023b42-89c9-4aca-eecb-217d278b7a01"
   },
   "outputs": [],
   "source": [
    "edu.sort_values(by='Value', ascending= False,inplace=True)\n",
    "edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmCq6MtY6w4r"
   },
   "source": [
    "Note that the `inplace` keyword means that the DataFrame will be overwritten, and hence no new DataFrame is returned. If instead of `ascending = False` we use `ascending = True`, the values are sorted in ascending order (i.e. from the smallest to the largest values).\n",
    "\n",
    "If we want to return to the original order, we can sort by an index using the `sort_index` function and specifying `axis=0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:22:35.433721Z",
     "start_time": "2020-02-24T16:22:35.419487Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RHAF8elM6w4s",
    "outputId": "ad81561c-d924-45e1-9d70-79db7938a6d3"
   },
   "outputs": [],
   "source": [
    "edu.sort_index(axis=0,ascending=True,inplace=True)\n",
    "edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTmz5_vW6w4u"
   },
   "source": [
    "## Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CcsmqFYK6w4u"
   },
   "source": [
    "Another very useful way to inspect data is to group it according to some criteria. For instance, in our example it would be nice to group all the data by country, regardless of the year. Pandas has the `groupby` function that allows us to do just that. The value returned by this function is a special grouped DataFrame. To have a proper DataFrame as a result, it is necessary to apply an aggregation function. Thus, this function will be applied to all the values in the same group.\n",
    "\n",
    "\n",
    "For example, in our case, if we want a DataFrame showing the mean of the values for each country over all the years, we can obtain it by grouping according to country and using the mean function as the aggregation method for each group. The result would be  a DataFrame with countries as indexes and the mean values as the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T10:57:09.266153Z",
     "start_time": "2019-11-12T10:57:09.229490Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EMBw-v7u6w4v",
    "outputId": "34ea9071-f201-41fa-c0a1-20b22fc8471e"
   },
   "outputs": [],
   "source": [
    "group=edu[[\"GEO\",\"Value\"]].groupby('GEO').mean()\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJ9-fBJK6w4x"
   },
   "source": [
    "## Rearranging Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1aQWcQ-6w4y"
   },
   "source": [
    "Up until now, our indexes have been just a numeration of rows without much meaning.  We can transform the arrangement of our data, redistributing the indexes and columns for better manipulation of our data, which normally leads to better performance. We can rearrange our data using the `pivot_table` function. Here, we can specify which columns will be the new indexes, the new values and the new columns. \n",
    "\n",
    "For example, imagine that we want to transform our DataFrame to a spreadsheet-like structure with the country names as the index, while the columns will be the years starting from 2006 and the values will be the previous *\"Value\"* column. To do this, first we need to filter out the data and then pivot it in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:25:01.728098Z",
     "start_time": "2020-02-24T16:25:01.693599Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KDuXXQ416w4y",
    "outputId": "e6f42841-bc37-4810-c39a-98d906654046"
   },
   "outputs": [],
   "source": [
    "filtered_data = edu[edu[\"TIME\"]>2005]  \n",
    "pivedu=pd.pivot_table(filtered_data, values='Value', index=['GEO'],columns = ['TIME'])\n",
    "pivedu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-Iw3N7c6w46"
   },
   "source": [
    "Now we can use the new index to select specific rows by label, using the `loc` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:25:03.050514Z",
     "start_time": "2020-02-24T16:25:03.043170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-KPysmt46w46",
    "outputId": "6321634d-a17f-4a6a-9485-18f1bbd47add"
   },
   "outputs": [],
   "source": [
    "pivedu.loc[['Spain','Portugal'],[2006,2011]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdCaHO2f6w47"
   },
   "source": [
    "Pivot also offers the option of providing an argument `aggr_function` that allows us to perform an aggregation function between the values if there is more than one value for the given row and column after the transformation. As usual, you can design any custom function you want, just giving its name or using a $\\lambda$-function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "915bzGhn6w48"
   },
   "source": [
    "## Ranking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Hir_44E6w48"
   },
   "source": [
    "Another useful visualization feature is to rank data. For example, we would like to know how  each country is ranked by year. To see this, we will use the pandas `rank` function. But first, we need to clean up our previous pivoted table a bit so that it only has real countries with real data. To do this, first we drop the Euro area entries and shorten the Germany name entry, using the `rename` function and then we drop all the rows containing any NaN, using the `dropna` function.\n",
    "\n",
    "Now we can perform the ranking using the `rank`function. Note here that the parameter `ascending=False` makes the ranking go from the highest values to the lowest values. The Pandas rank function supports different tie-breaking methods, specified with the `method` parameter. In our case, we use the  `first` method, in which ranks are assigned in the order they appear in the array, avoiding gaps between ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:25:09.385660Z",
     "start_time": "2020-02-24T16:25:09.365249Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ya5hgpY96w49",
    "outputId": "cbc4f90e-e17b-4192-8199-f3c73eef6072"
   },
   "outputs": [],
   "source": [
    "pivedu = pivedu.drop(['Euro area (13 countries)', \n",
    "                      'Euro area (15 countries)',\n",
    "                      'Euro area (17 countries)', \n",
    "                      'Euro area (18 countries)',\n",
    "                      'European Union (25 countries)',\n",
    "                      'European Union (27 countries)',\n",
    "                      'European Union (28 countries)'\n",
    "                      ], axis=0)\n",
    "pivedu= pivedu.rename(index={'Germany (until 1990 former territory of the FRG)': 'Germany'})\n",
    "pivedu = pivedu.dropna()\n",
    "pivedu.rank(ascending=False,method='first').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCsHU9BH6w4-"
   },
   "source": [
    "If we want to make a global ranking taking into account all the years, we can sum up all the columns and rank the result. Then we can sort the resulting values to retrieve the top 5 countries for the last 6 years, in this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:25:11.311148Z",
     "start_time": "2020-02-24T16:25:11.299550Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NpUgHBH_6w4-",
    "outputId": "88e68a29-8c5c-45ee-fabf-bb505d670d0b"
   },
   "outputs": [],
   "source": [
    "totalSum = pivedu.sum(axis=1)\n",
    "totalSum.rank(ascending=False,method='dense').sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Om-FSES6w4_"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y76g9wqM6w5A"
   },
   "source": [
    " Pandas DataFrames and Series can be plotted using the `plot` function, which uses the library for graphics *Matplotlib*.  \n",
    " \n",
    "For example, if we want to plot the accumulated values for each country over the last 6 years, we can take the  Series obtained in the previous example and plot it directly by calling the `plot` function: \n",
    "\n",
    "\n",
    "Note that if we want the bars ordered from the highest to the lowest value, we need to sort the values in the Series first. The parameter  `kind` used in the `plot` function defines which kind of graphic will be used. In our case, a bar graph. The parameter `style` refers to the style properties of the graphic, in our case, the color of bars is set to `b` (blue). The alpha channel can be modified adding a keyword parameter `alpha`  with a percentage, producing a more translucent plot. Finally, using the `title` keyword the name of the graphic can be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:25:15.528019Z",
     "start_time": "2020-02-24T16:25:13.921188Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sfara_Cb6w5A",
    "outputId": "faaea574-5e13-4c7c-e0e4-a179fa1ff887"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "totalSum=pivedu.sum(axis=1).sort_values(ascending=False)\n",
    "totalSum.plot(kind='bar',style='b', alpha=0.4,title = \"Total Values for Country\")\n",
    "plt.savefig(\"Totalvalue_Country.png\",dpi= 300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xf07Jpsn6w5B"
   },
   "source": [
    "It is also possible to plot a DataFrame directly. In this case, each column is treated as a separated Series. For example, instead of printing the accumulated value over the years, we can plot the value for each year.\n",
    "\n",
    "\n",
    "In this case, we have used a horizontal bar diagram (`kind='barh'`) stacking all the years in the same country bar. This can be done by setting the parameter `stacked` to `True`. The number of default colors in a plot is only 5, thus if you have more than 5 Series to show, you need to specify more colors or otherwise the same set of colors will be used again. We can set a new set of colors using the keyword `color` with a list of colors. Basic colors have a single-character code assigned to each, for example, \"b\" is for blue, \"r\" for red, \"g\" for green, \"y\" for yellow, \"m\" for magenta and \"c\" for cyan. When several Series are shown in a plot, a legend is created for identifying each one. The name for each Series is the name of the column in the DataFrame. By default, the legend goes inside the plot area. If we want to change this, we can use the `legend` function of the axis object (this is the object returned when the plot function is called). By using the `loc` keyword, we can set the relative position of the legend with respect to the plot. It can be a combination of right or left and upper, lower or center. With `bbox_to_anchor` we can set an absolute position with respect to the plot, allowing us to put the legend outside the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:25:21.799936Z",
     "start_time": "2020-02-24T16:25:20.547492Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tbt2n1Ks6w5C",
    "outputId": "966c03ce-79f2-4fb5-fe98-c9e427dd9def"
   },
   "outputs": [],
   "source": [
    "my_colors = ['b', 'r', 'g', 'y', 'm','c'] \n",
    "ax = pivedu.plot(kind='barh',stacked=True, color=my_colors,figsize=(12, 6))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "plt.savefig(\"Value_Time_Country.png\",dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0XlU2P_6w5G"
   },
   "source": [
    "# Further Reading\n",
    "Pandas has much more functionalities. Check out the (very readable) pandas docs if you want to learn more:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.1 Python_Toolbox.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
